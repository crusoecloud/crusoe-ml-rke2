apiVersion: kubeflow.org/v2beta1
kind: MPIJob
metadata:
  generateName: nccl-tests-gdr-16-
spec:
  slotsPerWorker: 8
  runPolicy:
    cleanPodPolicy: None
  mpiReplicaSpecs:
    Launcher:
      replicas: 1
      template:
        spec:
          restartPolicy: OnFailure
          initContainers:
          - image: crusoecloud/nccl-tests:h100-23.10-py3
            imagePullPolicy: Always
            name: init
            command: ["sh", "-c", "sleep 90"]
          volumes:
          - name: nccl-topo
            hostPath:
              path: /etc/crusoe/nccl_topo
              type: Directory
          containers:
          - image: crusoecloud/nccl-tests:h100-23.10-py3
            imagePullPolicy: Always
            volumeMounts:
            - name: nccl-topo
              mountPath: /opt/nccl_topo
            name: nccl-test-launcher
            securityContext:
              capabilities:
                add: ["IPC_LOCK"]
            env:
             - name: NCCL_TOPO_FILE
               value: /opt/nccl_topo/h100-80gb-sxm-ib-cloud-hypervisor.xml
             - name: UCX_RNDV_SCHEME
               value: "get_zcopy"   # UCX memory setting
             - name: UCX_TLS
               value: "self,sm,cuda_copy"   # UCX memory setting
            command:
            - /opt/hpcx/ompi/bin/mpirun
            - --allow-run-as-root
            - --tag-output
            - -np
            - "16"  # Total number of processes (8 GPUs per node, 2 nodes = 16 total if using 2 Worker Replicas)
            - -bind-to
            - none
            - -map-by
            - slot
            - -mca 
            - coll_hcoll_enable 
            - "0"
            - -x 
            - NCCL_IB_PCI_RELAXED_ORDERING=1
            - -x 
            - NCCL_IB_SPLIT_DATA_ON_QPS=0
            - -x 
            - NCCL_IB_QPS_PER_CONNECTION=2
            - -x
            - NCCL_IB_MERGE_VFS=0
            - -x
            - NCCL_IB_HCA=^mlx5_0:1 
            - -x
            - NCCL_IBEXT_DISABLE=1 
            - -x
            - NCCL_TOPO_FILE
            - -x
            - PATH
            - -x
            - LD_LIBRARY_PATH
            - -x
            - NCCL_DEBUG=TRACE
            - -x
            - NCCL_ALGO=NVLSTree
            - /opt/nccl-tests/build/all_reduce_perf
            - -b
            - "8"
            - -e
            - "2G"
            - -f
            - "2"
            - -t
            - "1"
            - -g
            - "1"
            - -c
            - "1"
            - -n
            - "100"
    Worker:
      replicas: 2 # Specify how many worker nodes you have running in the Instances tab
      template:
        spec:
          restartPolicy: OnFailure
          runtimeClassName: nvidia
          volumes:
          - name: dshm
            emptyDir:
              medium: Memory
              sizeLimit: 64Gi
          - name: nccl-topo
            hostPath:
              path: /etc/crusoe/nccl_topo
              type: Directory
          containers:
          - image: crusoecloud/nccl-tests:h100-23.10-py3
            imagePullPolicy: Always
            name: nccl-worker
            securityContext:
              capabilities:
                add: ["IPC_LOCK"]
            env:
             - name: NCCL_DEBUG
               value: TRACE
             - name: UCX_RNDV_SCHEME
               value: "get_zcopy"   # UCX memory setting
             - name: UCX_TLS
               value: "self,sm,cuda_copy"   # UCX memory setting
            volumeMounts:
            - mountPath: /dev/shm
              name: dshm
            - name: nccl-topo
              mountPath: /opt/nccl_topo
            resources:
              limits:
                nvidia.com/gpu: 8 # 8 GPUs per node
                nvidia.com/hostdev: 8
                memory: 128000Mi
              requests:
                nvidia.com/gpu: 8 # 8 GPUs per node
                nvidia.com/hostdev: 8
                memory: 128000Mi
